{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cba0ac-9469-4921-8e4b-5aa50537077b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' cannot use operands with types dtype('<m8[ns]') and dtype('O')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m material_data \u001b[38;5;241m=\u001b[39m df_melted[df_melted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterialNumber\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m material]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Forecast\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m forecast \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_material\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaterial_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Actual value\u001b[39;00m\n\u001b[1;32m     35\u001b[0m actual \u001b[38;5;241m=\u001b[39m material_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mforecast_material\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforecast_material\u001b[39m(data):\n\u001b[1;32m     19\u001b[0m     model \u001b[38;5;241m=\u001b[39m ARIMA(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 20\u001b[0m     model_fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     forecast \u001b[38;5;241m=\u001b[39m model_fit\u001b[38;5;241m.\u001b[39mforecast(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/statsmodels/tsa/arima/model.py:395\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     method_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 395\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_kwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_params:\n\u001b[1;32m    399\u001b[0m         res\u001b[38;5;241m.\u001b[39mfit_details \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mmlefit\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/mlemodel.py:650\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03mFits the model by maximum likelihood via Kalman filter.\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03mstatsmodels.tsa.statespace.structural.UnobservedComponentsResults\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     start_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_params\u001b[49m\n\u001b[1;32m    651\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    652\u001b[0m     includes_fixed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:953\u001b[0m, in \u001b[0;36mSARIMAX.start_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    949\u001b[0m     params_exog \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Non-seasonal ARMA component and trend\u001b[39;00m\n\u001b[1;32m    952\u001b[0m (params_trend, params_ar, params_ma,\n\u001b[0;32m--> 953\u001b[0m  params_variance) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conditional_sum_squares\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_ar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolynomial_ar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolynomial_ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_k_trend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarning_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mARMA and trend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# If we have estimated non-stationary start parameters but enforce\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;66;03m# stationarity is on, start with 0 parameters and warn\u001b[39;00m\n\u001b[1;32m    960\u001b[0m invalid_ar \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_ar \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_stationarity \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_invertible(np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mparams_ar])\n\u001b[1;32m    964\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:839\u001b[0m, in \u001b[0;36mSARIMAX._conditional_sum_squares\u001b[0;34m(endog, k_ar, polynomial_ar, k_ma, polynomial_ma, k_trend, trend_data, warning_description)\u001b[0m\n\u001b[1;32m    837\u001b[0m     X \u001b[38;5;241m=\u001b[39m lagmat(endog, k, trim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    838\u001b[0m     params_ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(X)\u001b[38;5;241m.\u001b[39mdot(Y)\n\u001b[0;32m--> 839\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m \u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_ar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# Run an ARMA(p,q) model using the just computed residuals as\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[1;32m    843\u001b[0m Y \u001b[38;5;241m=\u001b[39m endog[r:]\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' cannot use operands with types dtype('<m8[ns]') and dtype('O')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('practise_data_with_ABN_till_dec.csv')\n",
    "\n",
    "# Convert columns to datetime\n",
    "date_columns = df.columns[1:]\n",
    "df[date_columns] = df[date_columns].apply(pd.to_datetime)\n",
    "\n",
    "# Melt the dataframe to long format\n",
    "df_melted = df.melt(id_vars=['MaterialNumber'], var_name='Date', value_name='Sales')\n",
    "df_melted = df_melted.sort_values(['MaterialNumber', 'Date'])\n",
    "\n",
    "# Function to forecast for a single MaterialNumber\n",
    "def forecast_material(data):\n",
    "    model = ARIMA(data['Sales'].values[:-1], order=(1,1,1))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=1)\n",
    "    return forecast[0]\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Iterate through each MaterialNumber\n",
    "for material in df['MaterialNumber']:\n",
    "    material_data = df_melted[df_melted['MaterialNumber'] == material]\n",
    "    \n",
    "    # Forecast\n",
    "    forecast = forecast_material(material_data)\n",
    "    \n",
    "    # Actual value\n",
    "    actual = material_data['Sales'].values[-1]\n",
    "    \n",
    "    # Store results\n",
    "    results[material] = {'Forecast': forecast, 'Actual': actual}\n",
    "\n",
    "# Calculate overall MAPE\n",
    "y_true = [results[k]['Actual'] for k in results]\n",
    "y_pred = [results[k]['Forecast'] for k in results]\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Overall MAPE: {mape:.2%}\")\n",
    "\n",
    "# Print individual results\n",
    "for material, values in results.items():\n",
    "    print(f\"{material}: Forecast = {values['Forecast']:.2f}, Actual = {values['Actual']}, Error = {abs(values['Forecast'] - values['Actual']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041610cb-f84e-4be2-bf32-757046181f35",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MaterialNumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MaterialNumber'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m training_periods \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m36\u001b[39m]  \u001b[38;5;66;03m# 1 year, 2 years, 3 years\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m periods \u001b[38;5;129;01min\u001b[39;00m training_periods:\n\u001b[0;32m---> 81\u001b[0m     results, mape \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiods\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiods\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m months training period:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall MAPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmape\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m, in \u001b[0;36mforecast_and_evaluate\u001b[0;34m(df, train_periods)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforecast_and_evaluate\u001b[39m(df, train_periods):\n\u001b[1;32m     57\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m material \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMaterialNumber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     59\u001b[0m         material_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterialNumber\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m material]\n\u001b[1;32m     60\u001b[0m         material_data \u001b[38;5;241m=\u001b[39m add_features(material_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MaterialNumber'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_prepare_data(filepath, material_column='MaterialNumber'):\n",
    "    df = pd.read_csv(filepath)\n",
    "    if material_column not in df.columns:\n",
    "      raise ValueError(f\"Material column '{material_column}' not found in DataFrame.\")\n",
    "    unique_materials = df[material_column].unique()\n",
    "    prepared_data = []\n",
    "    for material in unique_materials:\n",
    "      df_material = df[df[material_column] == material].drop(material_column, axis=1).T\n",
    "      df_material.columns = ['Sales']  # Assuming 'Sales' for prepared data (modify as needed)\n",
    "      df_material.index = pd.to_datetime(df_material.index, format='%d-%m-%Y')\n",
    "      prepared_data.append(df_material)\n",
    "    return pd.concat(prepared_data, ignore_index=True)\n",
    "\n",
    "\n",
    "def forecast_arima(data, train_periods):\n",
    "    train = data['Sales'].values[-train_periods:-1]\n",
    "    model = ARIMA(train, order=(1,1,1))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=1)\n",
    "    return forecast[0]\n",
    "\n",
    "def forecast_prophet(data, train_periods):\n",
    "    train = data.iloc[-train_periods:-1].rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "    model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "    model.fit(train)\n",
    "    future = model.make_future_dataframe(periods=1, freq='M')\n",
    "    forecast = model.predict(future)\n",
    "    return forecast['yhat'].iloc[-1]\n",
    "\n",
    "def forecast_moving_average(data, window):\n",
    "    return data['Sales'].rolling(window=window).mean().iloc[-2]\n",
    "\n",
    "def ensemble_forecast(data, train_periods):\n",
    "    arima_forecast = forecast_arima(data, train_periods)\n",
    "    prophet_forecast = forecast_prophet(data, train_periods)\n",
    "    ma_forecast = forecast_moving_average(data, 3)\n",
    "    return np.mean([arima_forecast, prophet_forecast, ma_forecast])\n",
    "\n",
    "def add_features(data):\n",
    "    data['Month'] = data['Date'].dt.month\n",
    "    data['Year'] = data['Date'].dt.year\n",
    "    decomposition = seasonal_decompose(data['Sales'], model='additive', period=12)\n",
    "    data['Trend'] = decomposition.trend\n",
    "    data['Seasonality'] = decomposition.seasonal\n",
    "    return data\n",
    "\n",
    "def forecast_and_evaluate(df, train_periods):\n",
    "    results = {}\n",
    "    for material in df['MaterialNumber'].unique():\n",
    "        material_data = df[df['MaterialNumber'] == material]\n",
    "        material_data = add_features(material_data)\n",
    "        \n",
    "        forecast = ensemble_forecast(material_data, train_periods)\n",
    "        actual = material_data['Sales'].values[-1]\n",
    "        \n",
    "        results[material] = {'Forecast': forecast, 'Actual': actual}\n",
    "    \n",
    "    y_true = [results[k]['Actual'] for k in results]\n",
    "    y_pred = [results[k]['Forecast'] for k in results]\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "    return results, mape\n",
    "\n",
    "# Main execution\n",
    "file_path = 'practise_data_with_ABN_till_dec.csv'\n",
    "df = load_and_prepare_data(file_path)\n",
    "\n",
    "# Try different training periods\n",
    "training_periods = [12, 24, 36]  # 1 year, 2 years, 3 years\n",
    "\n",
    "for periods in training_periods:\n",
    "    results, mape = forecast_and_evaluate(df, periods)\n",
    "    \n",
    "    print(f\"\\nResults for {periods} months training period:\")\n",
    "    print(f\"Overall MAPE: {mape:.2%}\")\n",
    "    \n",
    "    # Print individual results (limiting to first 5 for brevity)\n",
    "    for i, (material, values) in enumerate(results.items()):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(f\"{material}: Forecast = {values['Forecast']:.2f}, Actual = {values['Actual']}, Error = {abs(values['Forecast'] - values['Actual']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cc406-d5fc-4b77-886f-6ec85ea43a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "255dde08-80e0-41fa-9469-7b73f8ef0428",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[1;32m     81\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpractise_data_with_ABN_till_dec.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 82\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Try different training periods\u001b[39;00m\n\u001b[1;32m     85\u001b[0m training_periods \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m36\u001b[39m]  \u001b[38;5;66;03m# 1 year, 2 years, 3 years\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mload_and_prepare_data\u001b[0;34m(filepath, material_column)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m material \u001b[38;5;129;01min\u001b[39;00m unique_materials:\n\u001b[1;32m     17\u001b[0m     df_material \u001b[38;5;241m=\u001b[39m df[df[material_column] \u001b[38;5;241m==\u001b[39m material]\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mdf_material\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaterialNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Assuming 'Sales' for prepared data (modify as needed)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     df_material\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_material\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     prepared_data\u001b[38;5;241m.\u001b[39mappend(df_material)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "def load_and_prepare_data(filepath, material_column=\"MaterialNumber\"):\n",
    "    df = pd.read_csv(filepath)\n",
    "    if material_column not in df.columns:\n",
    "        raise ValueError(f\"Material column '{material_column}' not found in DataFrame.\")\n",
    "\n",
    "    unique_materials = df[material_column].unique()\n",
    "    prepared_data = []\n",
    "    for material in unique_materials:\n",
    "        df_material = df[df[material_column] == material].drop(material_column, axis=1).T\n",
    "        df_material.columns = [\"Sales\"]  # Assuming 'Sales' for prepared data (modify as needed)\n",
    "        df_material.index = pd.to_datetime(df_material.index, format=\"%d-%m-%Y\")\n",
    "                df_material[\"Material\"] = material  # Add \"Material\" column with material name\n",
    "        prepared_data.append(df_material)\n",
    "    return pd.concat(prepared_data, ignore_index=True)\n",
    "\n",
    "\n",
    "def forecast_arima(data, train_periods):\n",
    "    train = data[\"Sales\"].values[-train_periods:]  # Use all data for training\n",
    "    model = ARIMA(train, order=(1, 1, 1))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=1)\n",
    "    return forecast[0]\n",
    "\n",
    "\n",
    "def forecast_prophet(data, train_periods):\n",
    "    train = data.iloc[-train_periods:].reset_index()  # Reset index for Prophet\n",
    "    train.columns = {\"Date\": \"ds\", \"Sales\": \"y\"}\n",
    "    model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "    model.fit(train)\n",
    "    future = model.make_future_dataframe(periods=1, freq=\"M\")\n",
    "    forecast = model.predict(future)\n",
    "    return forecast[\"yhat\"].iloc[-1]\n",
    "\n",
    "\n",
    "def forecast_moving_average(data, window):\n",
    "    return data[\"Sales\"].rolling(window=window).mean().iloc[-1]  # Use last value of MA\n",
    "\n",
    "\n",
    "def ensemble_forecast(data, train_periods):\n",
    "    arima_forecast = forecast_arima(data, train_periods)\n",
    "    prophet_forecast = forecast_prophet(data, train_periods)\n",
    "    ma_forecast = forecast_moving_average(data, 3)\n",
    "    return np.mean([arima_forecast, prophet_forecast, ma_forecast])\n",
    "\n",
    "\n",
    "def add_features(data):\n",
    "    data[\"Month\"] = data[\"Date\"].dt.month\n",
    "    data[\"Year\"] = data[\"Date\"].dt.year\n",
    "    decomposition = seasonal_decompose(data[\"Sales\"], model=\"additive\", period=12)\n",
    "    data[\"Trend\"] = decomposition.trend\n",
    "    data[\"Seasonality\"] = decomposition.seasonal\n",
    "    return data\n",
    "\n",
    "\n",
    "def forecast_and_evaluate(df, train_periods):\n",
    "    results = {}\n",
    "    for material in df[\"MaterialNumber\"].unique():\n",
    "        material_data = df[df[\"MaterialNumber\"] == material]\n",
    "        material_data = add_features(material_data)\n",
    "\n",
    "        forecast = ensemble_forecast(material_data, train_periods)\n",
    "        actual = material_data[\"Sales\"].values[-1]\n",
    "\n",
    "        results[material] = {\"Forecast\": forecast, \"Actual\": actual}\n",
    "\n",
    "    y_true = [results[k][\"Actual\"] for k in results]\n",
    "    y_pred = [results[k][\"Forecast\"] for k in results]\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "    return results, mape\n",
    "\n",
    "\n",
    "# Main execution\n",
    "file_path = \"practise_data_with_ABN_till_dec.csv\"\n",
    "df = load_and_prepare_data(file_path)\n",
    "\n",
    "# Try different training periods\n",
    "training_periods = [12, 24, 36]  # 1 year, 2 years, 3 years\n",
    "\n",
    "for periods in training_periods:\n",
    "    results, mape = forecast_and_evaluate(df, periods)\n",
    "\n",
    "    print(f\"\\nResults for {periods} months training period:\")\n",
    "    print(f\"Overall MAPE: {mape:.2%}\")\n",
    "\n",
    "    # Print individual results (limiting to first 5 for brevity)\n",
    "    for i, (material, values) in enumerate(results.items()):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(\n",
    "            f\"{material}: Forecast = {values['Forecast']:.2f}, Actual = {values['Actual']}, Error = {abs(values['Forecast'] - values['Actual']):.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51b23b-6884-40b4-b223-5358196fd732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
